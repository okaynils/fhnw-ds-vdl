{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vdl Depth and Class Constrained Diffusion\n",
    "- **Name:** Nils Fahrni\n",
    "- **Date:** 07.01.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "- 894 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "from data.nyuv2 import NYUDepthV2\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "image_t = transforms.Compose([\n",
    "    transforms.CenterCrop(400),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((1.3268, 1.1391, 1.0176), (0.5704, 0.5411, 0.5077))\n",
    "])\n",
    "\n",
    "crop_t = transforms.Compose([\n",
    "    transforms.CenterCrop(400)\n",
    "])\n",
    "\n",
    "dataset = NYUDepthV2(root='data', download=True, preload=False, image_transform=image_t, seg_transform=crop_t, depth_transform=crop_t)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20bede0eab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def unnormalize(img):\n",
    "    mean = torch.tensor([1.3268, 1.1391, 1.0176]).view(-1, 1, 1)  # Reshape to [C, 1, 1]\n",
    "    std = torch.tensor([0.5704, 0.5411, 0.5077]).view(-1, 1, 1)    # Reshape to [C, 1, 1]\n",
    "    img = std * img + mean\n",
    "    img = torch.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "plt.imshow(unnormalize(dataset[0][0]).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 23987843\n",
      "Output shape: torch.Size([3, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = 0\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "    def step_ema(self, ema_model, model, step_start_ema=2000):\n",
    "        if self.step < step_start_ema:\n",
    "            self.reset_parameters(ema_model, model)\n",
    "            self.step += 1\n",
    "            return\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels, in_channels // 2),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, 32)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, 16)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, 8)\n",
    "\n",
    "        self.bot1 = DoubleConv(256, 512)\n",
    "        self.bot2 = DoubleConv(512, 512)\n",
    "        self.bot3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, 16)\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, 32)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, 64)\n",
    "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t)\n",
    "        x4 = self.sa3(x4)\n",
    "\n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "\n",
    "        x = self.up1(x4, x3, t)\n",
    "        x = self.sa4(x)\n",
    "        x = self.up2(x, x2, t)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class UNet_conditional(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, num_classes=None, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, 32)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, 16)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, 8)\n",
    "\n",
    "        self.bot1 = DoubleConv(256, 512)\n",
    "        self.bot2 = DoubleConv(512, 512)\n",
    "        self.bot3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, 16)\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, 32)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, 64)\n",
    "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)\n",
    "\n",
    "        if num_classes is not None:\n",
    "            self.class_emb = nn.Linear(num_classes, time_dim)\n",
    "            self.depth_emb = nn.Linear(num_classes, time_dim)\n",
    "            self.t_proj = nn.Linear(3 * time_dim, time_dim)  # Project concatenated embeddings back to time_dim\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t, class_vector, depth_vector):\n",
    "        # Process time embedding\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "\n",
    "        # Process class and depth embeddings\n",
    "        class_emb = self.class_emb(class_vector)\n",
    "        depth_emb = self.depth_emb(depth_vector)\n",
    "\n",
    "        # Combine embeddings\n",
    "        t_combined = torch.cat([t, class_emb, depth_emb], dim=-1)\n",
    "        t_combined = self.t_proj(t_combined)\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t_combined)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t_combined)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t_combined)\n",
    "        x4 = self.sa3(x4)\n",
    "\n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "\n",
    "        x = self.up1(x4, x3, t_combined)\n",
    "        x = self.sa4(x)\n",
    "        x = self.up2(x, x2, t_combined)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t_combined)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output\n",
    "\n",
    "net = UNet_conditional(num_classes=894, device=\"cpu\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in net.parameters())}\")\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randn(3, 3, 64, 64)\n",
    "t = torch.randint(0, 1000, (x.shape[0],))\n",
    "class_vector = torch.zeros((x.shape[0], 894))\n",
    "depth_vector = torch.zeros((x.shape[0], 894))\n",
    "\n",
    "# Forward pass\n",
    "output = net(x, t, class_vector, depth_vector)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")\n",
    "\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    def sample(self, model, n, labels, cfg_scale=3):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                predicted_noise = model(x, t, labels)\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = model(x, t, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, diffusion, optimizer, epochs, device, train_dataloader, val_dataloader=None, run_name='diffusion_model', project_name='diffusion_project', save_dir='models', ema_decay=0.995):\n",
    "        self.model = model.to(device)\n",
    "        self.diffusion = diffusion\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.run_name = run_name\n",
    "        self.project_name = project_name\n",
    "        self.save_dir = save_dir\n",
    "        self.ema_decay = ema_decay\n",
    "\n",
    "        # Initialize EMA\n",
    "        self.ema = EMA(ema_decay)\n",
    "        self.ema_model = copy.deepcopy(model).eval().requires_grad_(False)\n",
    "\n",
    "        # Initialize Weights & Biases\n",
    "        wandb.init(project=self.project_name, name=self.run_name)\n",
    "        self.run_id = wandb.run.id\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "        # Create a models directory if it doesn't exist\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            pbar = tqdm(self.train_dataloader, desc=f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "            for i, (images, segs, depths, class_vectors, depth_vectors) in enumerate(pbar):\n",
    "                images = images.to(self.device)\n",
    "                class_vectors = class_vectors.to(self.device)\n",
    "                depth_vectors = depth_vectors.to(self.device)\n",
    "\n",
    "                # Sample time steps\n",
    "                t = self.diffusion.sample_timesteps(images.size(0)).to(self.device)\n",
    "\n",
    "                # Add noise to images\n",
    "                x_t, noise = self.diffusion.noise_images(images, t)\n",
    "\n",
    "                # Implement classifier-free guidance by dropping conditional vectors randomly\n",
    "                if torch.rand(1).item() < 0.1:\n",
    "                    class_vectors = None\n",
    "                    depth_vectors = None\n",
    "\n",
    "                # Predict noise using the model\n",
    "                predicted_noise = self.model(x_t, t, class_vectors, depth_vectors)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "                # Backpropagation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Update EMA model\n",
    "                self.ema.step_ema(self.ema_model, self.model)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "                # Log the loss\n",
    "                wandb.log({'train_loss': loss.item()})\n",
    "\n",
    "            avg_loss = epoch_loss / len(self.train_dataloader)\n",
    "            print(f\"Epoch [{epoch+1}/{self.epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            # Validate and save the model\n",
    "            if self.val_dataloader is not None:\n",
    "                val_loss = self.validate()\n",
    "                wandb.log({'val_loss': val_loss})\n",
    "                self._save_model(val_loss)\n",
    "            else:\n",
    "                self._save_model(avg_loss)\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, segs, depths, class_vectors, depth_vectors in self.val_dataloader:\n",
    "                images = images.to(self.device)\n",
    "                class_vectors = class_vectors.to(self.device)\n",
    "                depth_vectors = depth_vectors.to(self.device)\n",
    "\n",
    "                t = self.diffusion.sample_timesteps(images.size(0)).to(self.device)\n",
    "                x_t, noise = self.diffusion.noise_images(images, t)\n",
    "\n",
    "                predicted_noise = self.model(x_t, t, class_vectors, depth_vectors)\n",
    "                loss = F.mse_loss(predicted_noise, noise)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(self.val_dataloader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        return avg_val_loss\n",
    "\n",
    "    def _save_model(self, val_loss):\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            model_name = f\"{self.model.__class__.__name__}_{self.run_id}.pth\"\n",
    "            save_path = os.path.join(self.save_dir, model_name)\n",
    "            torch.save(self.model.state_dict(), save_path)\n",
    "            wandb.save(save_path)\n",
    "            print(f\"Model saved to {save_path} with val_loss {val_loss:.4f}\")\n",
    "\n",
    "    def sample(self, n_samples, class_vectors, depth_vectors, cfg_scale=3):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n_samples, 3, self.diffusion.img_size, self.diffusion.img_size)).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.diffusion.noise_steps)), desc='Sampling'):\n",
    "                t = torch.full((n_samples,), i, dtype=torch.long).to(self.device)\n",
    "                predicted_noise = self.model(x, t, class_vectors, depth_vectors)\n",
    "                if cfg_scale > 0:\n",
    "                    uncond_predicted_noise = self.model(x, t, None, None)\n",
    "                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "                alpha = self.diffusion.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.diffusion.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.diffusion.beta[t][:, None, None, None]\n",
    "                noise = torch.randn_like(x) if i > 1 else torch.zeros_like(x)\n",
    "                x = (1 / torch.sqrt(alpha)) * (x - ((1 - alpha) / torch.sqrt(1 - alpha_hat)) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "            x = (x.clamp(-1, 1) + 1) / 2  # Rescale images to [0, 1]\n",
    "            x = (x * 255).type(torch.uint8)  # Convert to uint8\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mokaynils\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\wandb\\run-20241127_174555-opr7v41r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/okaynils/vdl/runs/opr7v41r' target=\"_blank\">nyu_depth_diffusion</a></strong> to <a href='https://wandb.ai/okaynils/vdl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/okaynils/vdl' target=\"_blank\">https://wandb.ai/okaynils/vdl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/okaynils/vdl/runs/opr7v41r' target=\"_blank\">https://wandb.ai/okaynils/vdl/runs/opr7v41r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/182 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Initialize model\n",
    "num_classes = 894\n",
    "model = UNet_conditional(num_classes=num_classes, device=device)\n",
    "\n",
    "# Initialize diffusion process\n",
    "diffusion = Diffusion(img_size=64, device=device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    "    train_dataloader=train_loader,\n",
    "    run_name='nyu_depth_diffusion',\n",
    "    project_name='vdl',\n",
    "    save_dir='models'\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yo:   8%|▊         | 1/12 [00:04<00:48,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 64]) torch.Size([128, 400, 400]) torch.Size([128, 400, 400]) torch.Size([128, 894]) torch.Size([128, 894])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yo:  17%|█▋        | 2/12 [00:08<00:43,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 64]) torch.Size([128, 400, 400]) torch.Size([128, 400, 400]) torch.Size([128, 894]) torch.Size([128, 894])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yo:  17%|█▋        | 2/12 [00:12<01:00,  6.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_vectors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_vectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\data\\nyuv2.py:81\u001b[0m, in \u001b[0;36mNYUDepthV2.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     79\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[index]\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m     80\u001b[0m seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegments[index]\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m---> 81\u001b[0m depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Convert to numpy arrays\u001b[39;00m\n\u001b[0;32m     84\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\fahrn\\Documents\\Classes\\vdl\\fhnw-ds-vdl\\.venv\\Lib\\site-packages\\h5py\\_hl\\dataset.py:781\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "pbar = tqdm(dataloader, desc=f\"yo\")\n",
    "for i, (images, segs, depths, class_vectors, depth_vectors) in enumerate(pbar):\n",
    "    print(images.shape, segs.shape, depths.shape, class_vectors.shape, depth_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
